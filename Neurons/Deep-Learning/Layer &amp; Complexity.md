Typically, having deeper layers in a neural network allows for the computation of more complex data whilst lowering the computational cost to a complexity of $O(logn)$ 

The inverse, having a shallow network whilst inputting complex data into the model will require a model and it's computations to be increasingly complex with the weights increasing on the order of $O(2^n)$ as the input features increase

This is as the number of combinations with input values increase exponentially with the number of input dimensions.