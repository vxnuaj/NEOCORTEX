Eigendecomposition expresses a square matrix $A$ in terms of it's eigenvalues and eigenvectors. 

$A = V\Lambda V^-1$

where 

- $V$ is a matrix whose columns are eigenvectors of $A$
- $\Lambda$ is a diagonal matrix, containing the eigenvalues of all $A$ on the diagonal

Given $A$, we have an [[eigenvalue]] and an [[eigenvector]] that satisfies:

$Av = \lambda v$

When we apply a linear combination of the column vectors of $A$ with $v$ as $Av$, we get a multiple of $v$, the multiplier denoted by $\lambda$ which is the [[eigenvalue]] and the [[eigenvector]] is $v$.


---


why do we solve for zero vector when finding eigenvectors?